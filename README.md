# AcaRead-Academic-Paper-Analyzer-and-Summarizer
Our goal is to develop a tool that can quickly synthesize and condense key information from academic abstracts, allowing scholars to effectively grasp and utilize research findings without dedicating excessive time to reading each paper in full. In order to develop our product, we have incorporated various natural language processing techniques, including Named-Entity Recognition, Sentiment-Based Search, and Text Summarization using a Large Language Model. Specifically, some of the tools and technologies we used are SpaCy's Named Entity Recognition, scikit-learn's TfIdf Vectorizer, BERT's Sentence Embeddings, and a 4bit-quantized Mistral-7B LLM model trained on the Alpaca dataset.

To take a closer look at our methodology, our preprocessing consisted of different methods depending on the function and use of the abstract/query. There was no feature engineering conducted. In some cases, reformatting was conducted to fit sentences on one line. For Named Entity Recognition (NER), the only preprocessing conducted was splitting the abstract by sentences in order to better differentiate which named entities belonged to which sentence when displaying results. The query was not used. For TfidfVectorizer, we cleaned the abstracts through lowercasing, removing URLs, tokenization, stopword removal, and lemmatization, and also lowercased the query. For BERT Sentence Transformer, we cleaned the abstracts through lowercasing, splitting, and removing URLs, and also lowercased the query.  The textual data from the abstracts are then converted into numerical representations TfidfVectorizer. After vectorization we can then calculate the Euclidean distances and similarities between our abstracts and queries that we input. We then implemented BERT Sentence Transformer to convert sentences into high-dimensional vectors. These vectors were again compared using Euclidean similarity. Lasty, we incorporated the 4bit-quantized Mistral 7b LLM trained on yamha’s Alpaca dataset to generate coherent and concise summaries of the abstracts by understanding and paraphrasing the content. There was no cleaning or pre-processing conducted before employing the LLM.

Overall, all three of our methods were successful in completing their intended task; however, error analysis indicates that our summarizations and BERT sentence embedding distance scores could have been improved. Nevertheless, our sentiment-based search results were still reasonable. As an extension, we intend to account for BERT’s sentence embeddings’ shortcomings with encoding singular words and to evaluate our summaries with LSA or SummTriver to determine quantitative scores without reference summaries.
