{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# AcaRead"
      ],
      "metadata": {
        "id": "j7H5-HBJaeTQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HGGuZhuSFhB3"
      },
      "source": [
        "## 1. Load the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "sKW06qULF5k_"
      },
      "outputs": [],
      "source": [
        "# import string\n",
        "from sklearn.metrics.pairwise import euclidean_distances\n",
        "# import random\n",
        "# import gensim.downloader as api"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N5e5zBus5Mpe",
        "outputId": "8cd4d9df-79ef-4da8-c346-37c9bb9f5079"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                      categories  \\\n",
              "0                      ['cs.LG']   \n",
              "1             ['cs.LG', 'cs.AI']   \n",
              "2  ['cs.LG', 'cs.CR', 'stat.ML']   \n",
              "3             ['cs.LG', 'cs.CR']   \n",
              "4                      ['cs.LG']   \n",
              "\n",
              "                                              titles  \\\n",
              "0  Multi-Level Attention Pooling for Graph Neural...   \n",
              "1  Decision Forests vs. Deep Networks: Conceptual...   \n",
              "2  Power up! Robust Graph Convolutional Network v...   \n",
              "3  Releasing Graph Neural Networks with Different...   \n",
              "4  Recurrence-Aware Long-Term Cognitive Network f...   \n",
              "\n",
              "                                           abstracts  \n",
              "0  Graph neural networks (GNNs) have been widely ...  \n",
              "1  Deep networks and decision forests (such as ra...  \n",
              "2  Graph convolutional networks (GCNs) are powerf...  \n",
              "3  With the increasing popularity of Graph Neural...  \n",
              "4  Machine learning solutions for pattern classif...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c330845-dec1-4285-9c6e-713b284141c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>categories</th>\n",
              "      <th>titles</th>\n",
              "      <th>abstracts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>['cs.LG']</td>\n",
              "      <td>Multi-Level Attention Pooling for Graph Neural...</td>\n",
              "      <td>Graph neural networks (GNNs) have been widely ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>['cs.LG', 'cs.AI']</td>\n",
              "      <td>Decision Forests vs. Deep Networks: Conceptual...</td>\n",
              "      <td>Deep networks and decision forests (such as ra...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>['cs.LG', 'cs.CR', 'stat.ML']</td>\n",
              "      <td>Power up! Robust Graph Convolutional Network v...</td>\n",
              "      <td>Graph convolutional networks (GCNs) are powerf...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>['cs.LG', 'cs.CR']</td>\n",
              "      <td>Releasing Graph Neural Networks with Different...</td>\n",
              "      <td>With the increasing popularity of Graph Neural...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>['cs.LG']</td>\n",
              "      <td>Recurrence-Aware Long-Term Cognitive Network f...</td>\n",
              "      <td>Machine learning solutions for pattern classif...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c330845-dec1-4285-9c6e-713b284141c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3c330845-dec1-4285-9c6e-713b284141c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3c330845-dec1-4285-9c6e-713b284141c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1752dcbd-a784-4b3d-8ad5-602522c99e29\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1752dcbd-a784-4b3d-8ad5-602522c99e29')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1752dcbd-a784-4b3d-8ad5-602522c99e29 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df",
              "summary": "{\n  \"name\": \"df\",\n  \"rows\": 56181,\n  \"fields\": [\n    {\n      \"column\": \"categories\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3402,\n        \"samples\": [\n          \"['cs.LG', 'cs.CL', 'cs.CV', 'stat.ML']\",\n          \"['cs.LG', 'cs.AI', 'cs.CV', 'stat.ME', 'stat.ML']\",\n          \"['stat.ML', 'cs.LG', 'physics.chem-ph', 'physics.data-an']\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"titles\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41105,\n        \"samples\": [\n          \"Semi-supervised Federated Learning for Activity Recognition\",\n          \"SATR-DL: Improving Surgical Skill Assessment and Task Recognition in Robot-assisted Surgery with Deep Neural Networks\",\n          \"A Hybrid Stochastic Policy Gradient Algorithm for Reinforcement Learning\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"abstracts\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 41115,\n        \"samples\": [\n          \"Counterfactual inference has become a ubiquitous tool in online\\nadvertisement, recommendation systems, medical diagnosis, and econometrics.\\nAccurate modeling of outcome distributions associated with different\\ninterventions -- known as counterfactual distributions -- is crucial for the\\nsuccess of these applications. In this work, we propose to model counterfactual\\ndistributions using a novel Hilbert space representation called counterfactual\\nmean embedding (CME). The CME embeds the associated counterfactual distribution\\ninto a reproducing kernel Hilbert space (RKHS) endowed with a positive definite\\nkernel, which allows us to perform causal inference over the entire landscape\\nof the counterfactual distribution. Based on this representation, we propose a\\ndistributional treatment effect (DTE) that can quantify the causal effect over\\nentire outcome distributions. Our approach is nonparametric as the CME can be\\nestimated under the unconfoundedness assumption from observational data without\\nrequiring any parametric assumption about the underlying distributions. We also\\nestablish a rate of convergence of the proposed estimator which depends on the\\nsmoothness of the conditional mean and the Radon-Nikodym derivative of the\\nunderlying marginal distributions. Furthermore, our framework allows for more\\ncomplex outcomes such as images, sequences, and graphs. Our experimental\\nresults on synthetic data and off-policy evaluation tasks demonstrate the\\nadvantages of the proposed estimator.\",\n          \"Current multi-person localisation and tracking systems have an over reliance\\non the use of appearance models for target re-identification and almost no\\napproaches employ a complete deep learning solution for both objectives. We\\npresent a novel, complete deep learning framework for multi-person localisation\\nand tracking. In this context we first introduce a light weight sequential\\nGenerative Adversarial Network architecture for person localisation, which\\novercomes issues related to occlusions and noisy detections, typically found in\\na multi person environment. In the proposed tracking framework we build upon\\nrecent advances in pedestrian trajectory prediction approaches and propose a\\nnovel data association scheme based on predicted trajectories. This removes the\\nneed for computationally expensive person re-identification systems based on\\nappearance features and generates human like trajectories with minimal\\nfragmentation. The proposed method is evaluated on multiple public benchmarks\\nincluding both static and dynamic cameras and is capable of generating\\noutstanding performance, especially among other recently proposed deep neural\\nnetwork based approaches.\",\n          \"Unifying text detection and text recognition in an end-to-end training\\nfashion has become a new trend for reading text in the wild, as these two tasks\\nare highly relevant and complementary. In this paper, we investigate the\\nproblem of scene text spotting, which aims at simultaneous text detection and\\nrecognition in natural images. An end-to-end trainable neural network named as\\nMask TextSpotter is presented. Different from the previous text spotters that\\nfollow the pipeline consisting of a proposal generation network and a\\nsequence-to-sequence recognition network, Mask TextSpotter enjoys a simple and\\nsmooth end-to-end learning procedure, in which both detection and recognition\\ncan be achieved directly from two-dimensional space via semantic segmentation.\\nFurther, a spatial attention module is proposed to enhance the performance and\\nuniversality. Benefiting from the proposed two-dimensional representation on\\nboth detection and recognition, it easily handles text instances of irregular\\nshapes, for instance, curved text. We evaluate it on four English datasets and\\none multi-language dataset, achieving consistently superior performance over\\nstate-of-the-art methods in both detection and end-to-end text recognition\\ntasks. Moreover, we further investigate the recognition module of our method\\nseparately, which significantly outperforms state-of-the-art methods on both\\nregular and irregular text datasets for scene text recognition.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# read csv file\n",
        "df = pd.read_csv(\"arxiv_data_210930-054931.csv\", on_bad_lines = 'skip')\n",
        "df = df.rename(columns={\"summaries\":\"abstracts\", \"terms\": \"categories\"})\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We loaded the data from our CSV file as a pandas dataframe. We renamed some of the columns for clarity."
      ],
      "metadata": {
        "id": "Ih587qiADvd2"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LInQVnFV_Yv_"
      },
      "source": [
        "### 1.2 Create and Process Queries"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a useable UI interface that allows the user to input a number selecting from the range of abstracts from our large dataset and to create a sample query."
      ],
      "metadata": {
        "id": "wIRcHckjEMeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract abstracts\n",
        "abstracts = df[\"abstracts\"]"
      ],
      "metadata": {
        "id": "gfgWLYg9mSWJ"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xVM8JJ1r_lWI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e8a6b0d-b466-4d08-aedb-dafad072d35b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "56181"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "# check length of abstracts\n",
        "len(abstracts)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "index = 25221 # @param {type:\"slider\", min:0, max:56180, step:1}\n",
        "\n",
        "query = 'algorithm' # @param {type:\"string\"}"
      ],
      "metadata": {
        "id": "CBDduNxsal4a"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract = abstracts[index]\n",
        "# abstract = abstract.split(\"\\n\")\n",
        "# abstract = \" \".join(abstract)\n",
        "print(abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H39U9fquaoqy",
        "outputId": "2e469bd6-7a97-4015-bcfd-8a74b55f3cf6"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "In this paper, we propose a novel map for dense crowd localization and crowd\n",
            "counting. Most crowd counting methods utilize convolution neural networks (CNN)\n",
            "to regress a density map, achieving significant progress recently. However,\n",
            "these regression-based methods are often unable to provide a precise location\n",
            "for each person, attributed to two crucial reasons: 1) the density map consists\n",
            "of a series of blurry Gaussian blobs, 2) severe overlaps exist in the dense\n",
            "region of the density map. To tackle this issue, we propose a novel Focal\n",
            "Inverse Distance Transform (FIDT) map for crowd localization and counting.\n",
            "Compared with the density maps, the FIDT maps accurately describe the people's\n",
            "location, without overlap between nearby heads in dense regions. We\n",
            "simultaneously implement crowd localization and counting by regressing the FIDT\n",
            "map. Extensive experiments demonstrate that the proposed method outperforms\n",
            "state-of-the-art localization-based methods in crowd localization tasks,\n",
            "achieving very competitive performance compared with the regression-based\n",
            "methods in counting tasks. In addition, the proposed method presents strong\n",
            "robustness for the negative samples and extremely dense scenes, which further\n",
            "verifies the effectiveness of the FIDT map. The code and models are available\n",
            "at https://github.com/dk-liang/FIDTM.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = query.lower()\n",
        "print(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JqlcytyieWVY",
        "outputId": "b0e12b84-a8c8-44f7-8bac-e48e17a9f64c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "algorithm\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ebe9xpVUGfRz"
      },
      "source": [
        "## 2. Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1FWeCMxjGiL9",
        "outputId": "30ad30f5-b488-4ec0-9f23-cc11ef7d7125"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sentence 1:\n",
            "\n",
            "Sentence 2:\n",
            "cnn ORG\n",
            "\n",
            "Sentence 3:\n",
            "two CARDINAL\n",
            "1 CARDINAL\n",
            "blurry gaussian blobs PERSON\n",
            "2 CARDINAL\n",
            "\n",
            "Sentence 4:\n",
            "\n",
            "Sentence 5:\n",
            "\n",
            "Sentence 6:\n",
            "\n",
            "Sentence 7:\n",
            "\n",
            "Sentence 8:\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "\n",
        "# design a function that takes in an abstract as the input and the output as NER tags\n",
        "def ner_tag(abstract):\n",
        "  # put unique sentences in a list\n",
        "  sentences = abstract.split(\". \")\n",
        "  # process sentences and perform NER\n",
        "  nlp = spacy.load(\"en_core_web_sm\")\n",
        "  for i in range(len(sentences)):\n",
        "    print(f'Sentence {i+1}:')\n",
        "    doc = nlp(sentences[i])\n",
        "    for ent in doc.ents:\n",
        "      print(ent.text, ent.label_)\n",
        "    print()\n",
        "\n",
        "ner_tag(abstract)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnQcAseeGhth"
      },
      "source": [
        "## 3. Sentiment-Based Search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This step involves parsing through the abstract for sentences that match the sentiments of a given query. We employed two different methods in order to capture the texts numerically--TfIdf Vectorization and BERT Sentence Transformers. For each of these methods, we calculated and ranked the Euclidean distances between the vecotrs of each of the sentences and the query."
      ],
      "metadata": {
        "id": "ySB0cWQdFUU6"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jq0HIShdjqqs"
      },
      "source": [
        "### 3.1 TfIdf Vectorized-Based Search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to perform TfIdf Vectorization, we first cleaned the abstracts through lowercasing, removing URLs, tokenization, stopword removal, and lemmatization. Afterwards, we used scikit-learn's TfIdf Vectorizer to vectorize the corpus and vectorize the lowercased query. Finally, we calculated the Euclidean distances."
      ],
      "metadata": {
        "id": "Nke5SuIgGJV0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')\n",
        "\n",
        "# load a set of English stopwords from the NLTK library\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def clean(abstract):\n",
        "  # split abstract into sentences\n",
        "  sentences = abstract.split(\".\")\n",
        "  cleaned_abstract = []\n",
        "  for sent in sentences:\n",
        "    # lowercase the data\n",
        "    text = sent.lower()\n",
        "    # remove URLs\n",
        "    text = re.sub(r'http\\S+', '', text)\n",
        "    text = text.strip()\n",
        "    # tokenize the input text into individual tokens (words)\n",
        "    tokenized_text = word_tokenize(text)\n",
        "    # filter out any tokens that are in the list of stopwords\n",
        "    filtered_text = [token for token in tokenized_text if token not in stop_words]\n",
        "    # join the filtered tokens back into a single string, separated by spaces\n",
        "    filtered_text = \" \".join(filtered_text)\n",
        "    # lemmatize text\n",
        "    wnl = WordNetLemmatizer()\n",
        "    tokens = filtered_text.split()\n",
        "    lemmas = [wnl.lemmatize(token) for token in tokens]\n",
        "    lemmatized_text = \" \".join(lemmas)\n",
        "    cleaned_abstract.append(lemmatized_text)\n",
        "  return cleaned_abstract\n",
        "\n",
        "# call clean function\n",
        "cleaned_abstract = clean(abstract)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVLt5IT03y42",
        "outputId": "7f1b6889-1688-430f-d3be-a01307c35122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9MaDPtKkIY9",
        "outputId": "4fe1ddbb-52dd-4e08-aab5-6730fad3800a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary length 34\n",
            "N-Hot Vectorization:\n",
            "[0.21454733125344497, 0.0, 0.0, 0.0, 0.2550395756397351, 0.0, 0.0, 0.0, 0.0, 0.0, 0.19725208310305747, 0.0, 0.19725208310305747, 0.19725208310305747, 0.21454733125344497, 0.0, 0.21454733125344497, 0.0, 0.19725208310305747, 0.0, 0.19725208310305747, 0.19725208310305747, 0.21454733125344497, 0.19725208310305747, 0.2336663410727109, 0.2336663410727109, 0.2336663410727109, 0.21454733125344497, 0.2336663410727109, 0.2336663410727109, 0.2550395756397351, 0.0, 0.0, 0.30724315810790637]\n",
            "[0.16495088599974306, 0.0, 0.33292243287036155, 0.292786640315043, 0.1960826253162601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.15165374317664382, 0.0, 0.15165374317664382, 0.15165374317664382, 0.16495088599974306, 0.17965019542811453, 0.16495088599974306, 0.23621841787157874, 0.15165374317664382, 0.26165490099852584, 0.15165374317664382, 0.15165374317664382, 0.16495088599974306, 0.15165374317664382, 0.17965019542811453, 0.17965019542811453, 0.17965019542811453, 0.16495088599974306, 0.17965019542811453, 0.17965019542811453, 0.1960826253162601, 0.0, 0.23621841787157874, 0.23621841787157874]\n",
            "[0.13711403973792335, 0.0, 0.0, 0.24337643772918208, 0.16299203679070817, 0.24337643772918208, 0.0, 0.3237608386676559, 0.3237608386676559, 0.3237608386676559, 0.1260609013543556, 0.1963545775372403, 0.1260609013543556, 0.1260609013543556, 0.13711403973792335, 0.14933271734529854, 0.13711403973792335, 0.1963545775372403, 0.1260609013543556, 0.0, 0.1260609013543556, 0.1260609013543556, 0.13711403973792335, 0.1260609013543556, 0.14933271734529854, 0.14933271734529854, 0.14933271734529854, 0.13711403973792335, 0.14933271734529854, 0.14933271734529854, 0.16299203679070817, 0.24337643772918208, 0.1963545775372403, 0.0]\n",
            "[0.17500479884041265, 0.0, 0.35321437069473616, 0.3106322635428231, 0.20803404717465754, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1608971825593316, 0.0, 0.1608971825593316, 0.1608971825593316, 0.17500479884041265, 0.19060004511031833, 0.17500479884041265, 0.0, 0.1608971825593316, 0.2776030152085781, 0.1608971825593316, 0.1608971825593316, 0.17500479884041265, 0.1608971825593316, 0.19060004511031833, 0.19060004511031833, 0.19060004511031833, 0.17500479884041265, 0.19060004511031833, 0.19060004511031833, 0.20803404717465754, 0.0, 0.0, 0.2506161543265707]\n",
            "[0.17517479085984008, 0.4136318739540918, 0.0, 0.0, 0.20823612236358496, 0.0, 0.0, 0.0, 0.0, 0.0, 0.16105347105635956, 0.25085959191489626, 0.16105347105635956, 0.16105347105635956, 0.17517479085984008, 0.1907851856709541, 0.17517479085984008, 0.25085959191489626, 0.16105347105635956, 0.0, 0.16105347105635956, 0.16105347105635956, 0.17517479085984008, 0.16105347105635956, 0.1907851856709541, 0.1907851856709541, 0.1907851856709541, 0.17517479085984008, 0.1907851856709541, 0.1907851856709541, 0.20823612236358496, 0.0, 0.25085959191489626, 0.0]\n",
            "\n",
            "\n",
            "Printing top 3 most similar text for query ['algorithm']\n",
            "Score: 0.9233373202375117 --- addition , proposed method present strong robustness negative sample extremely dense scene , verifies effectiveness fidt map\n",
            "Score: 0.9603319373991399 --- compared density map , fidt map accurately describe people's location , without overlap nearby head dense region\n",
            "Score: 0.9828800212290713 --- paper , propose novel map dense crowd localization crowd counting\n"
          ]
        }
      ],
      "source": [
        "# vectorize abstract data to search by a sample query for the top 3 most similar sentences\n",
        "\n",
        "import numpy as np\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import pairwise_distances\n",
        "\n",
        "# perform tfidf vectorization\n",
        "# define the N for N-grams\n",
        "N = 1\n",
        "\n",
        "# initialize the TfIdfVectorizer with N-gram range\n",
        "tfidfvectorizer = TfidfVectorizer(ngram_range=(N, N), lowercase = False,binary = True, analyzer=lambda x:x, max_features = 1000)\n",
        "\n",
        "# fit and transform the corpus\n",
        "tfidfvectorizer.fit(cleaned_abstract)\n",
        "n_hot_matrix = tfidfvectorizer.transform(cleaned_abstract)\n",
        "\n",
        "# print the length of vocabulary (unique words)\n",
        "vocabulary_dict = tfidfvectorizer.vocabulary_\n",
        "print(f\"Vocabulary length {len(vocabulary_dict)}\")\n",
        "\n",
        "# convert the matrix to an array and print the result for the first 5 instances\n",
        "print(\"N-Hot Vectorization:\")\n",
        "for vec in n_hot_matrix.toarray().tolist()[:5]:\n",
        "  print(vec)\n",
        "\n",
        "# process and vectorize queries and then calculate Euclidean distance scores\n",
        "query = [query]\n",
        "queryVector = tfidfvectorizer.transform(query).toarray()\n",
        "distances = pairwise_distances(queryVector, n_hot_matrix.toarray(), metric='euclidean')[0]\n",
        "sorted_indices = np.argsort(distances)\n",
        "# print top 3 most similar queries\n",
        "print(\"\\n\")\n",
        "print (f\"Printing top 3 most similar text for query {query}\")\n",
        "for q in sorted_indices[:3]:\n",
        "  print(f'Score: {distances[q]} --- {cleaned_abstract[q]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For abstract_no 25221, these results accurately indicate that this abstract does not include the query word \"algorithm\" because all of the distances are greater than 0. Some of the sentences do seem to indicate functions or actions that would be well-represented by an algorithm, such as \"map dense crowd localization\" or \"fidt map,\" also known as Focal Inverse Distance Transform map. However, the search does seem to miss other potential matches of \"algorithm,\" like \"convolutional neural networks.\" Overall, the search results are somewhat reasonable for the given query."
      ],
      "metadata": {
        "id": "IT3VcU9QGwJW"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwx6m0tvWW3c"
      },
      "source": [
        "### 3.2 Sentence Transformer-Based Search"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to perform BERT Sentence Transformers, we first cleaned the abstracts through lowercasing, splitting, and removing URLs. Afterwards, we used the BERT model to get sentence embeddings for the abstract and the query. Finally, we calculated the Euclidean distances."
      ],
      "metadata": {
        "id": "wQ9O7iApIpXi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9D1-CTZXaRM",
        "outputId": "8b012393-e0e7-4c1b-fa67-7f986571f062"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: sentence_transformers in /usr/local/lib/python3.10/dist-packages (2.7.0)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.40.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (4.66.2)\n",
            "Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.25.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.2.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (1.11.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.15.1 in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (0.20.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from sentence_transformers) (9.4.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2023.6.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (2.31.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (6.0.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (4.11.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.15.1->sentence_transformers) (24.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (3.1.3)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->sentence_transformers) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.11.0->sentence_transformers) (12.4.127)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.34.0->sentence_transformers) (0.4.3)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (1.4.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->sentence_transformers) (3.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->sentence_transformers) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.15.1->sentence_transformers) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->sentence_transformers) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install sentence_transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NdT64tqNWvC7",
        "outputId": "32f62f0f-306a-43f5-8177-96dc3481490a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with MEAN pooling.\n",
            "WARNING:sentence_transformers.SentenceTransformer:No sentence-transformers model found with name bert-base-uncased. Creating a new one with MEAN pooling.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Printing top 3 most similar sentences for query: ['algorithm']\n",
            "Score: 9.567865371704102 --- we simultaneously implement crowd localization and counting by regressing the fidt map\n",
            "Score: 9.578535079956055 --- in this paper, we propose a novel map for dense crowd localization and crowd counting\n",
            "Score: 9.804736137390137 --- to tackle this issue, we propose a novel focal inverse distance transform (fidt) map for crowd localization and counting\n"
          ]
        }
      ],
      "source": [
        "# design a function that takes in an abstract as an input and then cleans and vectorizes the data,\n",
        "#so the output can be searched by a sample query for the top 3 most similar sentences\n",
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "# Load a pre-trained BERT model\n",
        "model = SentenceTransformer('bert-base-uncased')\n",
        "# Load a pre-trained BERT model\n",
        "model = SentenceTransformer('bert-base-uncased')\n",
        "\n",
        "#some cleaning\n",
        "# lowercase and split selected abstract text into sentences\n",
        "abstract_lower = abstract.lower()\n",
        "abstract_lower = abstract_lower.split(\"\\n\")\n",
        "abstract_lower = \" \".join(abstract_lower)\n",
        "# remove URLs\n",
        "abstract_cleaned = re.sub(r'http\\S+', '', abstract_lower)\n",
        "abstract_sentences = abstract_cleaned.split(\".\")\n",
        "abstract_sentences = [i for i in abstract_sentences if i]\n",
        "abstract_sentences = [i.strip() for i in abstract_sentences]\n",
        "\n",
        "# generate sentence embeddings\n",
        "sentence_embeddings = model.encode(abstract_sentences)\n",
        "\n",
        "# lowercase and embed query\n",
        "query_embedding = model.encode(query)\n",
        "query_embedding_flat = query_embedding.reshape(1, -1)  # Reshape the query embedding to have a single sample\n",
        "\n",
        "# iterate through sentences and generate distances\n",
        "distances = []\n",
        "for sent in range(len(abstract_sentences)):\n",
        "    distance = pairwise_distances(query_embedding_flat, sentence_embeddings[sent].reshape(1, -1), metric='euclidean')[0][0]\n",
        "    distances.append(distance)\n",
        "\n",
        "sorted_indices = np.argsort(distances)\n",
        "# print top 3 most similar queries\n",
        "print(\"\\n\")\n",
        "print (f\"Printing top 3 most similar sentences for query: {query}\")\n",
        "for q in sorted_indices[:3]:\n",
        "    print(f'Score: {distances[q]} --- {abstract_sentences[q]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For abstract_no 25221, these results accurately indicate that this abstract does not include the query word \"algorithm\" because all of the distances are much greater than 0. Similar to the TfIdf vectorization results, some of the sentences do seem to indicate actions that would be well-represented by an algorithm. However, this sentiment-based search also seems to miss other potential matches of \"algorithm,\" like \"convolutional neural networks.\" Overall, the search results are somewhat reasonable for the given query. Unlike the search results with TfIdf vectorization, the distance scores are much higher with the sentence embeddings. This is likely because BERT sentence embeddings are not always well-suited to generate embeddings for singular words. So, although our results were similar across both sentiment-based searches, the distance scores of the BERT sentence embedding-based search may be skewed due to the attempt to encode a single word query with no context."
      ],
      "metadata": {
        "id": "ePK7zCNdJw3k"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0oC-NfVdCjhH"
      },
      "source": [
        "## 4. Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We intend to use the Mistral 7b Large Language Model (LLM) trained on yamha's Alpaca dataset to attempt to summarize a given abstract."
      ],
      "metadata": {
        "id": "hzQGs8_1MEeG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l_Gw9IFyFNCn",
        "outputId": "641de1a1-f607-4556-eefe-95987f198e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mistralai\n",
            "  Downloading mistralai-0.1.8-py3-none-any.whl (15 kB)\n",
            "Collecting httpx<0.26.0,>=0.25.2 (from mistralai)\n",
            "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.10 (from mistralai)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3.0.0,>=2.5.2 in /usr/local/lib/python3.10/dist-packages (from mistralai) (2.7.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<0.26.0,>=0.25.2->mistralai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx<0.26.0,>=0.25.2->mistralai) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<0.26.0,>=0.25.2->mistralai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3.0.0,>=2.5.2->mistralai) (4.11.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx<0.26.0,>=0.25.2->mistralai) (1.2.1)\n",
            "Installing collected packages: orjson, h11, httpcore, httpx, mistralai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.25.2 mistralai-0.1.8 orjson-3.10.1\n"
          ]
        }
      ],
      "source": [
        "pip install mistralai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "OtXjSzJf3w5k"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "import torch\n",
        "major_version, minor_version = torch.cuda.get_device_capability()\n",
        "# Must install separately since Colab has torch 2.2.1, which breaks packages\n",
        "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
        "if major_version >= 8:\n",
        "    # Use this for new GPUs like Ampere, Hopper GPUs (RTX 30xx, RTX 40xx, A100, H100, L40)\n",
        "    !pip install --no-deps packaging ninja einops flash-attn xformers trl peft accelerate bitsandbytes\n",
        "else:\n",
        "    # Use this for older GPUs (V100, Tesla T4, RTX 20xx)\n",
        "    !pip install --no-deps xformers trl peft accelerate bitsandbytes\n",
        "pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We download the 4bit quantized version of Mistral 7b to prevent Google Colab from crashing."
      ],
      "metadata": {
        "id": "jWZksXyQUtf7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OdISdEjY4afm",
        "outputId": "1a246a5a-e95e-485e-faa1-766dbce12347"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "==((====))==  Unsloth: Fast Mistral patching release 2024.4\n",
            "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
            "O^O/ \\_/ \\    Pytorch: 2.2.1+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
            "\\        /    Bfloat16 = FALSE. Xformers = 0.0.25.post1. FA = False.\n",
            " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Unused kwargs: ['quant_method']. These kwargs are not used in <class 'transformers.utils.quantization_config.BitsAndBytesConfig'>.\n"
          ]
        }
      ],
      "source": [
        "from unsloth import FastLanguageModel\n",
        "import torch\n",
        "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
        "dtype = None # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
        "load_in_4bit = True # Use 4bit quantization to reduce memory usage. Can be False.\n",
        "\n",
        "# 4bit pre quantized Mistral 7b we support for 4x faster downloading + no OOMs.\n",
        "fourbit_models = [\n",
        "    \"unsloth/mistral-7b-bnb-4bit\",\n",
        "    \"unsloth/mistral-7b-instruct-v0.2-bnb-4bit\",\n",
        "] # More models at https://huggingface.co/unsloth\n",
        "\n",
        "model, tokenizer = FastLanguageModel.from_pretrained(\n",
        "    model_name = \"unsloth/mistral-7b-bnb-4bit\", # Choose ANY! eg teknium/OpenHermes-2.5-Mistral-7B\n",
        "    max_seq_length = max_seq_length,\n",
        "    dtype = dtype,\n",
        "    load_in_4bit = load_in_4bit,\n",
        "    # token = \"hf_...\", # use one if using gated models like meta-llama/Llama-2-7b-hf\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We LoRA adaptors to make finetuning more efficient later on."
      ],
      "metadata": {
        "id": "L2cLPU_QVMj0"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "acs_xnvG5mal"
      },
      "outputs": [],
      "source": [
        "model = FastLanguageModel.get_peft_model(\n",
        "    model,\n",
        "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
        "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
        "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
        "    lora_alpha = 16,\n",
        "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
        "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
        "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
        "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
        "    random_state = 3407,\n",
        "    use_rslora = False,  # We support rank stabilized LoRA\n",
        "    loftq_config = None, # And LoftQ\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are training Mistral 7b on the Alpaca dataset from yahma, which is a filtered version of the larger original Alpaca dataset. The Alpaca dataset is trained on completing a variety of tasks based on an instruction, input, and output."
      ],
      "metadata": {
        "id": "dQrTqZh2VhOQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "F6I9R2itXxoY"
      },
      "outputs": [],
      "source": [
        "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
        "\n",
        "### Instruction:\n",
        "{}\n",
        "\n",
        "### Input:\n",
        "{}\n",
        "\n",
        "### Response:\n",
        "{}\"\"\"\n",
        "\n",
        "\n",
        "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
        "def formatting_prompts_func(examples):\n",
        "    instructions = examples[\"instruction\"]\n",
        "    inputs       = examples[\"input\"]\n",
        "    outputs      = examples[\"output\"]\n",
        "    texts = []\n",
        "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
        "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
        "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
        "        texts.append(text)\n",
        "    return { \"text\" : texts, }\n",
        "pass\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"yahma/alpaca-cleaned\", split = \"train\")\n",
        "dataset = dataset.map(formatting_prompts_func, batched = True,)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to download several packages to ensure that we can probably use HuggingFace's SFTTrainer"
      ],
      "metadata": {
        "id": "m65TA44XV3y2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJKRaLAicD4o",
        "outputId": "fb10318e-f509-4f83-e0aa-794b25dd562d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
            "  Cloning https://github.com/huggingface/trl.git (to revision 7630f877f91c556d9e5a3baa4b6e2894d90ff84c) to /tmp/pip-req-build-psxaw14r\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/trl.git /tmp/pip-req-build-psxaw14r\n",
            "  Running command git rev-parse -q --verify 'sha^7630f877f91c556d9e5a3baa4b6e2894d90ff84c'\n",
            "  Running command git fetch -q https://github.com/huggingface/trl.git 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
            "  Running command git checkout -q 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
            "  Resolved https://github.com/huggingface/trl.git to commit 7630f877f91c556d9e5a3baa4b6e2894d90ff84c\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.12.dev0) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.12.dev0) (4.40.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.12.dev0) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl==0.7.12.dev0) (0.29.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl==0.7.12.dev0) (2.19.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl==0.7.12.dev0) (0.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.12.dev0) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.12.dev0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.12.dev0) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.12.dev0) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.19.3 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl==0.7.12.dev0) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl==0.7.12.dev0)\n",
            "  Using cached nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.22.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl==0.7.12.dev0) (4.66.2)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl==0.7.12.dev0) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl==0.7.12.dev0) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.12.dev0) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.12.dev0) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.12.dev0) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.12.dev0) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.12.dev0) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.12.dev0) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl==0.7.12.dev0) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.12.dev0) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.12.dev0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.12.dev0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl==0.7.12.dev0) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl==0.7.12.dev0) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl==0.7.12.dev0) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.12.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.12.dev0) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl==0.7.12.dev0) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl==0.7.12.dev0) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl==0.7.12.dev0) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl==0.7.12.dev0) (1.16.0)\n",
            "Building wheels for collected packages: trl\n",
            "  Building wheel for trl (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for trl: filename=trl-0.7.12.dev0-py3-none-any.whl size=173433 sha256=7bff876a007638870d826d0b466ffcf450226c8255f592e6ca7949da8583898a\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/f5/b1/f5ac48230936583c88cfde8596bc92cad4b0a4b24d0f819c06\n",
            "Successfully built trl\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, trl\n",
            "  Attempting uninstall: trl\n",
            "    Found existing installation: trl 0.8.6\n",
            "    Uninstalling trl-0.8.6:\n",
            "      Successfully uninstalled trl-0.8.6\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xformers 0.0.25.post1 requires torch==2.2.2, but you have torch 2.2.1+cu121 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105 trl-0.7.12.dev0\n"
          ]
        }
      ],
      "source": [
        "pip install git+https://github.com/huggingface/trl.git@7630f877f91c556d9e5a3baa4b6e2894d90ff84c"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to ensure that we have installed the trl library for finetuning"
      ],
      "metadata": {
        "id": "bMIcJseuWNbR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install trl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VYkGkAyohUZH",
        "outputId": "9834223d-bce5-41bd-b263-f5438b45e1a0"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: trl in /usr/local/lib/python3.10/dist-packages (0.7.12.dev0)\n",
            "Requirement already satisfied: torch>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from trl) (2.2.1+cu121)\n",
            "Requirement already satisfied: transformers>=4.31.0 in /usr/local/lib/python3.10/dist-packages (from trl) (4.40.0)\n",
            "Requirement already satisfied: numpy>=1.18.2 in /usr/local/lib/python3.10/dist-packages (from trl) (1.25.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (from trl) (0.29.3)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (from trl) (2.19.0)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl) (0.8.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.13.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.4.0->trl) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.4.0->trl) (12.4.127)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.22.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (24.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.31.0->trl) (4.66.2)\n",
            "Requirement already satisfied: docstring-parser>=0.14.1 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (0.16)\n",
            "Requirement already satisfied: rich>=11.1.0 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (13.7.1)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl) (1.7.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate->trl) (5.9.5)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.6)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (2.0.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (0.70.16)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->trl) (3.9.5)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->trl) (4.0.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.31.0->trl) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=11.1.0->tyro>=0.5.11->trl) (2.16.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.4.0->trl) (2.1.5)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets->trl) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.4.0->trl) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=11.1.0->tyro>=0.5.11->trl) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->trl) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUI3BMgNZbfM",
        "outputId": "a23eb016-4f6b-46f6-8392-5b3f5d962128"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "max_steps is given, it will override any value given in num_train_epochs\n"
          ]
        }
      ],
      "source": [
        "#from datasets import load_dataset\n",
        "from trl import SFTTrainer\n",
        "from transformers import (AutoTokenizer, AutoConfig,\n",
        "                              AutoModelForSequenceClassification, TrainingArguments, Trainer)\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    tokenizer = tokenizer,\n",
        "    train_dataset = dataset,\n",
        "    dataset_text_field = \"text\",\n",
        "    max_seq_length = max_seq_length,\n",
        "    dataset_num_proc = 2,\n",
        "    packing = False, # Can make training 5x faster for short sequences.\n",
        "    args = TrainingArguments(\n",
        "        per_device_train_batch_size = 2,\n",
        "        gradient_accumulation_steps = 4,\n",
        "        warmup_steps = 5,\n",
        "        max_steps = 60, # Set num_train_epochs = 1 for full training runs\n",
        "        learning_rate = 2e-4,\n",
        "        fp16 = not torch.cuda.is_bf16_supported(),\n",
        "        bf16 = torch.cuda.is_bf16_supported(),\n",
        "        logging_steps = 1,\n",
        "        optim = \"adamw_8bit\",\n",
        "        weight_decay = 0.01,\n",
        "        lr_scheduler_type = \"linear\",\n",
        "        seed = 3407,\n",
        "        output_dir = \"outputs\",\n",
        "    ),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer_stats = trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VbCs5A2M6ipx",
        "outputId": "b41f32de-6d7d-428c-98bf-cb176fe2af3a"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [60/60 08:22, Epoch 0/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.415100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.840600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.339500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.324900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.101300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>1.020300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.785600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.949700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.846000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.932100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.756300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.791200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.778000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.921300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.734500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.762000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.856900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>1.051700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.852200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>20</td>\n",
              "      <td>0.713200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>21</td>\n",
              "      <td>0.788000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>22</td>\n",
              "      <td>0.836000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>23</td>\n",
              "      <td>0.742800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>24</td>\n",
              "      <td>0.802300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>25</td>\n",
              "      <td>0.902800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>26</td>\n",
              "      <td>0.906200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>27</td>\n",
              "      <td>0.884200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>28</td>\n",
              "      <td>0.738800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>29</td>\n",
              "      <td>0.746900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>30</td>\n",
              "      <td>0.765600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>31</td>\n",
              "      <td>0.740400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>32</td>\n",
              "      <td>0.746600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>33</td>\n",
              "      <td>0.831300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>34</td>\n",
              "      <td>0.710300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>35</td>\n",
              "      <td>0.793100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>36</td>\n",
              "      <td>0.737300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>37</td>\n",
              "      <td>0.753900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>38</td>\n",
              "      <td>0.631100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>39</td>\n",
              "      <td>0.919900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>40</td>\n",
              "      <td>0.967300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>41</td>\n",
              "      <td>0.737900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>42</td>\n",
              "      <td>0.815200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>43</td>\n",
              "      <td>0.753100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>44</td>\n",
              "      <td>0.732600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>45</td>\n",
              "      <td>0.747100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>46</td>\n",
              "      <td>0.791200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>47</td>\n",
              "      <td>0.701300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>48</td>\n",
              "      <td>0.962800</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>49</td>\n",
              "      <td>0.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>50</td>\n",
              "      <td>0.848600</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>51</td>\n",
              "      <td>0.845300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>52</td>\n",
              "      <td>0.792300</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>53</td>\n",
              "      <td>0.832500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>54</td>\n",
              "      <td>0.981900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>55</td>\n",
              "      <td>0.661500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>56</td>\n",
              "      <td>0.873000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>57</td>\n",
              "      <td>0.743900</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>58</td>\n",
              "      <td>0.674700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>59</td>\n",
              "      <td>0.695400</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>60</td>\n",
              "      <td>0.752700</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "After we trained the model on a speedier run of 60 epoches, we can test the model. We will instruct the model to summarize our given abstract."
      ],
      "metadata": {
        "id": "HYm8EJZCYWMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract the abstracts\n",
        "\n",
        "# alpaca_prompt = Copied from above\n",
        "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
        "inputs = tokenizer(\n",
        "[\n",
        "    alpaca_prompt.format(\n",
        "        \"Provide a brief and concise summary of the input. Do not exactly repeat or reuse text from the input.\", # instruction\n",
        "        abstract, # input\n",
        "        \"\", # output - leave this blank for generation!\n",
        "    )\n",
        "], return_tensors = \"pt\").to(\"cuda\")\n",
        "\n",
        "from transformers import TextStreamer\n",
        "text_streamer = TextStreamer(tokenizer)\n",
        "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 200)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTU3TZsd9RVp",
        "outputId": "f318c2f9-b2fa-40d3-856a-204bf87d8b21"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<s> Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
            "\n",
            "### Instruction:\n",
            "Provide a brief and concise summary of the input. Do not exactly repeat or reuse text from the input.\n",
            "\n",
            "### Input:\n",
            "In this paper, we propose a novel map for dense crowd localization and crowd\n",
            "counting. Most crowd counting methods utilize convolution neural networks (CNN)\n",
            "to regress a density map, achieving significant progress recently. However,\n",
            "these regression-based methods are often unable to provide a precise location\n",
            "for each person, attributed to two crucial reasons: 1) the density map consists\n",
            "of a series of blurry Gaussian blobs, 2) severe overlaps exist in the dense\n",
            "region of the density map. To tackle this issue, we propose a novel Focal\n",
            "Inverse Distance Transform (FIDT) map for crowd localization and counting.\n",
            "Compared with the density maps, the FIDT maps accurately describe the people's\n",
            "location, without overlap between nearby heads in dense regions. We\n",
            "simultaneously implement crowd localization and counting by regressing the FIDT\n",
            "map. Extensive experiments demonstrate that the proposed method outperforms\n",
            "state-of-the-art localization-based methods in crowd localization tasks,\n",
            "achieving very competitive performance compared with the regression-based\n",
            "methods in counting tasks. In addition, the proposed method presents strong\n",
            "robustness for the negative samples and extremely dense scenes, which further\n",
            "verifies the effectiveness of the FIDT map. The code and models are available\n",
            "at https://github.com/dk-liang/FIDTM.\n",
            "\n",
            "### Response:\n",
            "The input proposes a novel map for dense crowd localization and counting. The\n",
            "proposed map, called Focal Inverse Distance Transform (FIDT) map, is designed\n",
            "to accurately describe the location of people in dense crowds, without overlap\n",
            "between nearby heads. The FIDT map is used to simultaneously implement crowd\n",
            "localization and counting by regressing the FIDT map. The proposed method\n",
            "outperforms state-of-the-art localization-based methods in crowd localization\n",
            "tasks, achieving very competitive performance compared with regression-based\n",
            "methods in counting tasks. The code and models are available at https://github.com/dk-liang/FIDTM.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For this given abstract, this summary incorporates a lot of the original vocabulary. However, it does alter the sentence structure and increase concision. Through altering the prompt for specificity and experimenting with the max_new_tokens count, we were able to determine a method through which we could ensure a summary that differed from the original input. For instance, having too large of a max_new_tokens value results in the model's response almost completely copying the input text. In the future, this summarization could be improved by incorporating a more diverse vocabulary and reusing less words from the original document. For our future work, we would like to more quantitatively analyze the quality of the summary, potentially using Latent Semantic Analysis. If we had the resources available, it would be ideal to have reference summaries for our abstracts to better gauge the quality of the model's summaries."
      ],
      "metadata": {
        "id": "YZk2Wjn1YmBf"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}